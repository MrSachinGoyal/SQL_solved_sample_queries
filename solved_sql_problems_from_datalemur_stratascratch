# Question: 
Assume you are given the table below on Uber transactions made by users. Write a query to obtain the third transaction of every user. 
Output the user id, spend and transaction date.

>> Creating the Table:
CREATE TABLE transactions (
  user_id INTEGER,
  spend DECIMAL,
  transaction_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO transactions (user_id, spend, transaction_date)
VALUES
  (111, 100.50, '2022-01-08 12:00:00'),
  (111, 55.00, '2022-01-10 12:00:00'),
  (121, 36.00, '2022-01-18 12:00:00'),
  (145, 24.99, '2022-01-26 12:00:00'),
  (111, 89.60, '2022-02-05 12:00:00');

>> My Solution:
WITH transaction_rank AS (SELECT *,
                          ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY transaction_date ASC) AS transaction_number
                          FROM transactions)
  
SELECT user_id, spend, transaction_date
FROM transaction_rank
WHERE transaction_number = 3;


# Question:
Assume you're given tables with information on Snapchat users, including their ages and time spent sending and opening snaps.
Write a query to obtain a breakdown of the time spent sending vs. opening snaps as a percentage of total time spent on these activities grouped by age group. 
Round the percentage to 2 decimal places in the output.

Notes:
Calculate the following percentages:
time spent sending / (Time spent sending + Time spent opening)
Time spent opening / (Time spent sending + Time spent opening)
To avoid integer division in percentages, multiply by 100.0 and not 100.

>> Creating the Table:
CREATE TABLE activities (
activity_id INTEGER,
user_id INTEGER,
activity_type VARCHAR(10),
time_spent FLOAT,
activity_date TIMESTAMP
);

CREATE TABLE age_breakdown (
user_id INTEGER,
age_bucket VARCHAR(10)
);

>> Inserting Data:
INSERT INTO activities (activity_id, user_id, activity_type, time_spent, activity_date)
VALUES
(7274, 123, 'open', 4.50, '2022-06-22 12:00:00'),
(2425, 123, 'send', 3.50, '2022-06-22 12:00:00'),
(1413, 456, 'send', 5.67, '2022-06-23 12:00:00'),
(1414, 789, 'chat', 11.00, '2022-06-25 12:00:00'),
(2536, 456, 'open', 3.00, '2022-06-25 12:00:00');

INSERT INTO age_breakdown (user_id, age_bucket)
VALUES
(123, '31-35'),
(456, '26-30'),
(789, '21-25');

>> My Solution:
WITH cte AS (SELECT t1.age_bucket, t2.user_id, t2.activity_type, t2.time_spent,
      			 SUM(time_spent) OVER(PARTITION BY age_bucket ORDER BY age_bucket ASC) AS total_time_spent
      			 FROM age_breakdown t1
      			 INNER JOIN 
      			 activities t2
      			 ON t1.user_id = t2.user_id
      			 WHERE activity_type IN ('send', 'open'))
			
SELECT age_bucket,
	   ROUND(SUM(CASE WHEN activity_type = 'send' THEN (time_spent*100.0)/total_time_spent ELSE NULL END),2) AS send_percent,
	   ROUND(SUM(CASE WHEN activity_type = 'open' THEN (time_spent*100.0)/total_time_spent ELSE NULL END),2) AS open_percent
FROM cte
GROUP BY age_bucket;

# Question:
Assume you're given a table containing data on Amazon customers and their spending on products in different category, write a query to identify the top two highest-grossing products 
within each category in the year 2022. 
The output should include the category, product, and total spend.

>> Creating Table:
CREATE TABLE product_spend (
  category VARCHAR(255),
  product VARCHAR(255),
  user_id INT,
  spend DECIMAL(10, 2),
  transaction_date TIMESTAMP
);

>>Inserting Data:
INSERT INTO product_spend (category, product, user_id, spend, transaction_date)
VALUES
  ('appliance', 'refrigerator', 165, 246.00, '2021-12-26 12:00:00'),
  ('appliance', 'refrigerator', 123, 299.99, '2022-03-02 12:00:00'),
  ('appliance', 'washing machine', 123, 219.80, '2022-03-02 12:00:00'),
  ('electronics', 'vacuum', 178, 152.00, '2022-04-05 12:00:00'),
  ('electronics', 'wireless headset', 156, 249.90, '2022-07-08 12:00:00'),
  ('electronics', 'vacuum', 145, 189.00, '2022-07-15 12:00:00');

>> My Solution:
SELECT category, product, total_spend
FROM
	(SELECT category, 
	        product, 
	        SUM(spend) AS total_spend,
	        RANK() OVER(PARTITION BY category ORDER BY SUM(spend) DESC) AS rank_by_total_spend
	FROM product_spend
	WHERE EXTRACT(YEAR FROM transaction_date) = 2022
	GROUP BY 1, 2) tmp
WHERE rank_by_total_spend < 3;

# Question:
Assume you're given a table Twitter tweet data, write a query to obtain a histogram of tweets posted per user in 2022. Output the tweet count per user as the bucket and the number of 
Twitter users who fall into that bucket. In other words, group the users by the number of tweets they posted in 2022 and count the number of users in each group.

>> Creating Table:
CREATE TABLE tweets (
    tweet_id INTEGER,
    user_id INTEGER,
    msg VARCHAR(1000),
    tweet_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO tweets (tweet_id, user_id, msg, tweet_date)
	VALUES
		(214252, 111, 'Am considering taking Tesla private at $420. Funding secured.', '2021-12-30 00:00:00'),
		(739252, 111, 'Despite the constant negative press covfefe', '2022-01-01 00:00:00'),
		(846402, 111, 'Following @NickSinghTech on Twitter changed my life!', '2022-02-14 00:00:00'),
		(241425, 254, 'If the salary is so competitive why wonâ€™t you tell me what it is?', '2022-03-01 00:00:00'),
		(231574, 148, 'I no longer have a manager. I can''t be managed', '2022-03-23 00:00:00');

>> My Solution:
WITH user_tweet_counts AS (SELECT user_id, 
						   		  COUNT(tweet_id) AS no_of_tweets_by_user
						   FROM tweets
						   WHERE EXTRACT(YEAR FROM tweet_date) = 2022
						   GROUP BY user_id)

SELECT no_of_tweets_by_user AS tweet_bucket,
       COUNT(user_id) AS num_users
FROM user_tweet_counts
GROUP BY tweet_bucket;

# Question:
Assume you're given a table containing information on Facebook user actions. 
Write a query to obtain number of monthly active users (MAUs) in July 2022, including the month in numerical format "1, 2, 3".

Hint: An active user is defined as a user who has performed actions such as 'sign-in', 'like', or 'comment' in both the current month and the previous month

>> Creating Table:
CREATE TABLE user_actions (
    user_id INTEGER,
    event_id INTEGER,
    event_type VARCHAR(255),
    event_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO user_actions (user_id, event_id, event_type, event_date)
VALUES
    (445, 7765, 'sign-in', '2022-05-31 12:00:00'),
    (742, 6458, 'sign-in', '2022-06-03 12:00:00'),
    (445, 3634, 'like', '2022-06-05 12:00:00'),
    (742, 1374, 'comment', '2022-06-05 12:00:00'),
    (648, 3124, 'like', '2022-06-18 12:00:00');

>> My Solution:
WITH active_users AS (
    SELECT user_id, 
           EXTRACT(month FROM event_date) AS month, 
           COUNT(EVENT_ID) AS num_events
    FROM USER_actions
    WHERE event_type IN ('sign-in', 'like', 'comment')
    GROUP BY user_id, EXTRACT(month FROM event_date)
    ORDER BY user_id
)

SELECT month, 
       COUNT(user_id) AS monthly_active_users
FROM (
    SELECT *,
           month - LAG(month, 1) OVER(PARTITION BY USER_ID ORDER BY month) AS month_diff
    FROM active_users
) tmp
WHERE month_diff = 1 AND month = 7
GROUP BY month;

# Question:
Assume there are three Spotify tables: artists, songs, and global_song_rank, which contain information about the artists, songs, and music charts, respectively.

Write a query to find the top 5 artists whose songs appear most frequently in the Top 10 of the global_song_rank table. Display the top 5 artist names in ascending order, 
along with their song appearance ranking.

Assumptions:
If two or more artists have the same number of song appearances, they should be assigned the same ranking, and the rank numbers should be continuous (i.e. 1, 2, 2, 3, 4, 5).
For instance, if both Ed Sheeran and Bad Bunny appear in the Top 10 five times, they should both be ranked 1st and the next artist should be ranked 2nd.

>> Creating Table:
CREATE TABLE artists (
    artist_id INTEGER,
    artist_name VARCHAR(255),
    label_owner VARCHAR(255)
);

CREATE TABLE songs (
    song_id INTEGER PRIMARY KEY,
    artist_id INTEGER,
    name VARCHAR(255)
);

CREATE TABLE global_song_rank (
    day INTEGER CHECK (day >= 1 AND day <= 52),
    song_id INTEGER,
    rank INTEGER CHECK (rank >= 1 AND rank <= 1000000)
);

>> Inserting data:
INSERT INTO artists (artist_id, artist_name, label_owner)
VALUES
    (101, 'Ed Sheeran', 'Warner Music Group'),
    (120, 'Drake', 'Warner Music Group'),
    (125, 'Bad Bunny', 'Rimas Entertainment');

INSERT INTO songs (song_id, artist_id, name)
VALUES
    (55511, 101, 'Perfect'),
    (45202, 101, 'Shape of You'),
    (22222, 120, 'One Dance'),
    (19960, 120, 'Hotline Bling');

INSERT INTO global_song_rank (day, song_id, rank)
VALUES
    (1, 45202, 5),
    (3, 45202, 2),
    (1, 19960, 3),
    (9, 19960, 15);

>> My Solution:
WITH top_ten AS (SELECT a.artist_name,
				         DENSE_RANK() OVER(ORDER BY COUNT(*) DESC) AS rank_by_num_song_appearences
								 FROM artists a 
								 INNER JOIN songs s 
								 ON a.artist_id = s.artist_id
								 INNER JOIN global_song_rank gsr
								 ON s.song_id = gsr.song_id
								 WHERE gsr.rank < 11 
								 GROUP BY a.artist_name)
					 
SELECT * FROM top_ten 
WHERE rank_by_num_song_appearences < 6;

# Question:
Assume you're given a table containing information about Wayfair user transactions for different products. 
Write a query to calculate the year-on-year growth rate for the total spend of each product, grouping the results by product ID.
The output should include the year in ascending order, product ID, current year's spend, previous year's spend and year-on-year growth percentage, rounded to 2 decimal places.

>> Creating Table:
CREATE TABLE user_transactions (
    transaction_id INTEGER,
    product_id INTEGER,
    spend DECIMAL(10, 2),
    transaction_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO user_transactions (transaction_id, product_id, spend, transaction_date)
VALUES
    (1341, 123424, 1500.60, '2019-12-31 12:00:00'),
    (1423, 123424, 1000.20, '2020-12-31 12:00:00'),
    (1623, 123424, 1246.44, '2021-12-31 12:00:00'),
    (1322, 123424, 2145.32, '2022-12-31 12:00:00');

>> My Solution:
WITH product_spend_cte AS (SELECT EXTRACT(YEAR FROM transaction_date) AS year,
              								    product_id,
              								    SUM(spend) AS current_year_spend_on_product,
              								    LAG(SUM(spend), 1) OVER(PARTITION BY product_id 
              														                ORDER BY EXTRACT(YEAR FROM transaction_date) ASC) AS previous_year_spend_on_product
              						 FROM user_transactions
              						 GROUP BY product_id, EXTRACT(YEAR FROM transaction_date))
							
SELECT *, 
	     ROUND(((current_year_spend_on_product - previous_year_spend_on_product)*100)/previous_year_spend_on_product, 2) AS year_on_year_growth_rate
FROM product_spend_cte;

# Question:
A Microsoft Azure Supercloud customer is defined as a company that purchases at least one product from each product category.
Write a query that effectively identifies the company ID of such Supercloud customers.

>> Creating Table:
CREATE TABLE customer_contracts (
    customer_id INTEGER,
    product_id INTEGER,
    amount INTEGER
);

CREATE TABLE products (
    product_id INTEGER,
    product_category VARCHAR(255),
    product_name VARCHAR(255)
);

>> Inserting Data:
INSERT INTO customer_contracts (customer_id, product_id, amount)
VALUES
    (1, 1, 1000),
    (1, 3, 2000),
    (1, 5, 1500),
    (2, 2, 3000),
    (2, 6, 2000);

INSERT INTO products (product_id, product_category, product_name)
VALUES
    (1, 'Analytics', 'Azure Databricks'),
    (2, 'Analytics', 'Azure Stream Analytics'),
    (4, 'Containers', 'Azure Kubernetes Service'),
    (5, 'Containers', 'Azure Service Fabric'),
    (6, 'Compute', 'Virtual Machines'),
    (7, 'Compute', 'Azure Functions');

>> My Solution:
SELECT cc.customer_id
FROM customer_contracts cc
INNER JOIN products p
ON cc.product_id = p.product_id
GROUP BY cc.customer_id
HAVING COUNT(DISTINCT p.product_category) = (SELECT COUNT(DISTINCT product_category) FROM products);

# Question:
Given a table of candidates and their skills, you're tasked with finding the candidates best suited for an open Data Science job. 
You want to find candidates who are proficient in Python, Tableau, and PostgreSQL.
Write a query to list the candidates who possess all of the required skills for the job. Sort the output by candidate ID in ascending order.

>> Creating Table:
CREATE TABLE candidates (
    candidate_id INTEGER,
    skill VARCHAR(255)
);

>> Inserting Data:
INSERT INTO candidates (candidate_id, skill)
VALUES
    (123, 'Python'),
    (123, 'Tableau'),
    (123, 'PostgreSQL'),
    (234, 'R'),
    (234, 'PowerBI'),
    (234, 'SQL Server'),
    (345, 'Python'),
    (345, 'Tableau');

>> My Solution:
SELECT candidate_id
FROM candidates
GROUP BY candidate_id
HAVING SUM(CASE WHEN skill in ('Python', 'Tableau', 'PostgreSQL') THEN 1 ELSE 0 END) = 3
ORDER BY candidate_id;

# Question:
Amazon wants to maximize the number of items it can stock in a 500,000 square feet warehouse. It wants to stock as many prime items as possible, and afterwards use the remaining 
square footage to stock the most number of non-prime items.

Write a query to find the number of prime and non-prime items that can be stored in the 500,000 square feet warehouse. Output the item type with prime_eligible followed by not_prime 
and the maximum number of items that can be stocked.

Assumptions:
-- Prime and non-prime items have to be stored in equal amounts, regardless of their size or square footage. This implies that prime items will be stored separately from non-prime 
   items in their respective containers, but within each container, all items must be in the same amount.
-- Non-prime items must always be available in stock to meet customer demand, so the non-prime item count should never be zero.
-- Item count should be whole numbers (integers).

>> Creating Table:
CREATE TABLE inventory (
    item_id INTEGER,
    item_type VARCHAR(255),
    item_category VARCHAR(255),
    square_footage DECIMAL
);

>> Inserting Data:
INSERT INTO inventory (item_id, item_type, item_category, square_footage)
VALUES
    (1374, 'prime_eligible', 'mini refrigerator', 68.00),
    (4245, 'not_prime', 'standing lamp', 26.40),
    (2452, 'prime_eligible', 'television', 85.00),
    (3255, 'not_prime', 'side table', 22.60),
    (1672, 'prime_eligible', 'laptop', 8.50);

>> My Solution:
WITH cte AS (SELECT item_type, COUNT(*) AS no_of_items,
			 SUM(square_footage) AS container_space, 500000 as total_sq_foot
			 FROM inventory
			 GROUP BY item_type
			 ORDER BY item_type DESC)
			 
SELECT item_type,
CASE WHEN item_type = 'prime_eligible' THEN FLOOR((total_sq_foot/container_space)) * no_of_items
ELSE FLOOR(
        	 (total_sq_foot - ( 
                					   SELECT container_space * FLOOR((total_sq_foot/container_space))
                					   FROM cte
                					   WHERE item_type = 'prime_eligible'
                					  )
        	 )/container_space
        	 ) * no_of_items
END AS item_count;

# Question:
Tesla is investigating production bottlenecks and they need your help to extract the relevant data. 
Write a query to determine which parts have begun the assembly process but are not yet finished.

Assumptions:
-- parts_assembly table contains all parts currently in production, each at varying stages of the assembly process.
-- An unfinished part is one that lacks a finish_date.

>> Creating Table:
CREATE TABLE parts_assembly (
    part VARCHAR(255),      
    finish_date TIMESTAMP,   
    assembly_step INT    
);

>> Inserting Table:
INSERT INTO parts_assembly (part, finish_date, assembly_step)
VALUES ('battery', '2022-01-22 00:00:00', 1),
       ('battery', '2022-02-22 00:00:00', 2),
       ('battery', '2022-03-22 00:00:00', 3),
       ('bumper', '2022-01-22 00:00:00', 1),
       ('bumper', '2022-02-22 00:00:00', 2),
       ('bumper', NULL, 3),
       ('bumper', NULL, 4);
	   
>> My Solution:
SELECT part,
	     assembly_step
FROM parts_assembly
WHERE finish_date IS NULL;

# Question:
Google's marketing team is making a Superbowl commercial and needs a simple statistic to put on their TV ad: the median number of searches a person made last year.
However, at Google scale, querying the 2 trillion searches is too costly. Luckily, you have access to the summary table which tells you the number of searches made last year and 
how many Google users fall into that bucket.
Write a query to report the median of searches made by a user. Round the median to one decimal point.

>> Creating table:
CREATE TABLE search_frequency (
    searches integer,
    num_users integer
);

>> Inserting data:
INSERT INTO search_frequency (searches, num_users)
VALUES
    (1, 2),
    (2, 2),
    (3, 3),
    (4, 1);

>> My Solution:
SELECT 
	(CAST (PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY searches) AS DECIMAL (6,1))) AS  median_searches 
FROM
(SELECT searches,
        GENERATE_SERIES(1, num_users) AS num_users
FROM search_frequency) tmp;

# Question:
Your team at JPMorgan Chase is soon launching a new credit card. You are asked to estimate how many cards you'll issue in the first month.
Before you can answer this question, you want to first get some perspective on how well new credit card launches typically do in their first month.

Write a query that outputs the name of the credit card, and how many cards were issued in its launch month. 
The launch month is the earliest record in the monthly_cards_issued table for a given card. Order the results starting from the biggest issued amount.

>> Creating Table:
CREATE TABLE monthly_cards_issued (
    issue_month INTEGER,
    issue_year INTEGER,
    card_name VARCHAR(255),
    issued_amount INTEGER
);

>> Inserting Data:
INSERT INTO monthly_cards_issued (issue_month, issue_year, card_name, issued_amount)
VALUES
    (1, 2021, 'Chase Sapphire Reserve', 170000),
    (2, 2021, 'Chase Sapphire Reserve', 175000),
    (3, 2021, 'Chase Sapphire Reserve', 180000),
    (3, 2021, 'Chase Freedom Flex', 65000),
    (4, 2021, 'Chase Freedom Flex', 70000);

>> My Solution:
SELECT card_name, issued_amount
FROM monthly_cards_issued
WHERE (card_name, 
       CAST(CONCAT(issue_year, '-', issue_month, '-', 1) AS DATE)) 
IN (SELECT card_name, 
	    MIN(CAST(CONCAT(issue_year, '-', issue_month, '-', 1) AS DATE)) AS first_issue_date
    FROM monthly_cards_issued
    GROUP BY card_name)
    ORDER BY issued_amount DESC;

# Question:
Assume you're given a table with measurement values obtained from a Google sensor over multiple days with measurements taken multiple times within each day.

Write a query to calculate the sum of odd-numbered and even-numbered measurements separately for a particular day and display the results in two different columns. 
Refer to the Example Output below for the desired format.

Definition:
Within a day, measurements taken at 1st, 3rd, and 5th times are considered odd-numbered measurements, and measurements taken at 2nd, 4th, and 6th times are considered even-numbered 
measurements.

>> Creating table:
CREATE TABLE measurements (
    measurement_id INTEGER,
    measurement_value DECIMAL,
    measurement_time TIMESTAMP
);

>> Inserting Data:
INSERT INTO measurements (measurement_id, measurement_value, measurement_time)
VALUES
    (131233, 1109.51, '2022-07-10 09:00:00'),
    (135211, 1662.74, '2022-07-10 11:00:00'),
    (523542, 1246.24, '2022-07-10 13:15:00'),
    (143562, 1124.50, '2022-07-11 15:00:00'),
    (346462, 1234.14, '2022-07-11 16:45:00');

>> My Solution:
WITH cte AS (SELECT CAST(DATE(measurement_time) AS TIMESTAMP) AS measurement_day,
				   	        measurement_value,
				   	        ROW_NUMBER() OVER(PARTITION BY DATE(measurement_time) 
									                    ORDER BY measurement_time ASC) AS measurement_num
			       FROM measurements)

SELECT measurement_day,
       SUM(CASE WHEN (measurement_num % 2 != 0) THEN measurement_value 
                ELSE 0 
                END) AS sum_odd,
       SUM(CASE WHEN (measurement_num % 2 = 0) THEN measurement_value 
                ELSE 0 
                END) AS sum_even
FROM cte
GROUP BY measurement_day
ORDER BY measurement_day;

# Question:
New TikTok users sign up with their emails. They confirmed their signup by replying to the text confirmation to activate their accounts. Users may receive multiple text messages 
for account confirmation until they have confirmed their new account.
A senior analyst is interested to know the activation rate of specified users in the emails table. Write a query to find the activation rate. Round the percentage to 2 decimal places.

Definitions:
emails table contain the information of user signup details.
texts table contains the users' activation information.

Assumptions:
The analyst is interested in the activation rate of specific users in the emails table, which may not include all users that could potentially be found in the texts table.
For example, user 123 in the emails table may not be in the texts table and vice versa.

>> Creating Table:
CREATE TABLE emails (
    email_id INTEGER,
    user_id INTEGER,
    signup_date TIMESTAMP
);

CREATE TABLE texts (
    text_id INTEGER,
    email_id INTEGER,
    signup_action VARCHAR(255) 
);

>> Inserting Data:
INSERT INTO emails (email_id, user_id, signup_date)
VALUES
    (125, 7771, '2022-06-14 00:00:00'),
    (236, 6950, '2022-07-01 00:00:00'),
    (433, 1052, '2022-07-09 00:00:00');

INSERT INTO texts (text_id, email_id, signup_action)
VALUES
    (6878, 125, 'Confirmed'),
    (6920, 236, 'Not Confirmed'),
    (6994, 236, 'Confirmed');

>> My Solution:
WITH user_activation_status AS (
    SELECT e.user_id, t.signup_action
    FROM emails e
    LEFT JOIN texts t ON e.email_id = t.email_id
    WHERE e.email_id IS NOT NULL 
),    
cte1 AS (
    SELECT COUNT(user_id) AS total_confirmed_users
    FROM user_activation_status
    WHERE signup_action = 'Confirmed'
),
cte2 AS (
    SELECT COUNT(DISTINCT user_id) AS total_num_users
    FROM user_activation_status
)

SELECT ROUND(CAST(total_confirmed_users AS DECIMAL) / total_num_users, 2) AS activation_percentage
FROM cte1, cte2;

# Question:
Assume you're given the table on user viewership categorised by device type where the three types are laptop, tablet, and phone.
Write a query that calculates the total viewership for laptops and mobile devices where mobile is defined as the sum of tablet and phone viewership. 
Output the total viewership for laptops as laptop_reviews and the total viewership for mobile devices as mobile_views.

>> Creating Table:
CREATE TABLE viewership (
    user_id INT,
    device_type VARCHAR(255), -- You can adjust the maximum length as needed
    view_time TIMESTAMP
);

>> Inserting Data:
INSERT INTO viewership (user_id, device_type, view_time)
VALUES
    (123, 'tablet', '2022-01-02 00:00:00'),
    (125, 'laptop', '2022-01-07 00:00:00'),
    (128, 'laptop', '2022-02-09 00:00:00'),
    (129, 'phone', '2022-02-09 00:00:00'),
    (145, 'tablet', '2022-02-24 00:00:00');

>> My Solution:
SELECT
COUNT(CASE WHEN device_type = 'laptop' THEN 1 ELSE NULL END) AS laptop_views,
COUNT(CASE WHEN device_type IN ('tablet', 'phone') THEN 1 ELSE NULL END) AS mobile_views
FROM viewership;


# Question: 
A phone call is considered an international call when the person calling is in a different country than the person receiving the call.
What percentage of phone calls are international? Round the result to 1 decimal.
	
Assumption: The caller_id in phone_info table refers to both the caller and receiver.

>> Creating table:
	CREATE TABLE phone_calls (
    caller_id INT,
    receiver_id INT,
    call_time TIMESTAMP
);

CREATE TABLE phone_info (
    caller_id INTEGER,
    country VARCHAR(255),
    network VARCHAR(255),
    phone_number CHAR(20) 
);

>> Inserting Data:
INSERT INTO phone_calls (caller_id, receiver_id, call_time)
VALUES
    (1, 2, '2022-07-04 10:13:49'),
    (1, 5, '2022-08-21 23:54:56'),
    (5, 1, '2022-05-13 17:24:06'),
    (5, 6, '2022-03-18 12:11:49');

INSERT INTO phone_info (caller_id, country, network, phone_number)
VALUES
    (1, 'US', 'Verizon', '+1-212-897-1964'),
    (2, 'US', 'Verizon', '+1-703-346-9529'),
    (3, 'US', 'Verizon', '+1-650-828-4774'),
    (4, 'US', 'Verizon', '+1-415-224-6663'),
    (5, 'IN', 'Vodafone', '+91 7503-907302'),
    (6, 'IN', 'Vodafone', '+91 2287-664895');

>> My Solution:
SELECT 
	   ROUND(
      100 * SUM(CASE 
                 WHEN caller_info.country_id <> receiver_info.country_id
                 THEN 1 ELSE NULL END)
            /COUNT(*),1
          ) AS int_calls_percent
FROM phone_calls pc
LEFT JOIN phone_info caller_info
ON pc.caller_id = caller_info.caller_id
LEFT JOIN phone_info receiver_info
ON pc.receiver_id = receiver_info.caller_id;
	

# Question:
Assume you're given a table on Walmart user transactions. Based on their most recent transaction date, write a query that retrieve the users along with the number of products 
they bought. Output the user's most recent transaction date, user ID, and the number of products, sorted in chronological order by the transaction date.

>> Creating Table:
CREATE TABLE user_transactions (
    product_id integer,
    user_id integer,
    spend decimal,
    transaction_date timestamp
);

>> Inserting Data:
INSERT INTO user_transactions (product_id, user_id, spend, transaction_date)
VALUES
    (3673, 123, 68.90, '2022-07-08 12:00:00'),
    (9623, 123, 274.10, '2022-07-08 12:00:00'),
    (1467, 115, 19.90, '2022-07-08 12:00:00'),
    (2513, 159, 25.00, '2022-07-08 12:00:00'),
    (1452, 159, 74.50, '2022-07-10 12:00:00');

>> My Solution:
WITH RankedTransactions AS (
    SELECT
        transaction_date,
        user_id,
        product_id,
        RANK() OVER (PARTITION BY user_id ORDER BY transaction_date DESC) AS rank_transaction_date
    FROM
        user_transactions
)

SELECT
    transaction_date,
    user_id,
    COUNT(product_id) AS num_products_bought
FROM
    RankedTransactions
WHERE
    rank_transaction_date = 1
GROUP BY
    transaction_date, user_id
ORDER BY
    transaction_date;

# Question: 
You have been asked to find the 5 most lucrative products in terms of total revenue for the first half of 2022 (from January to June inclusive).
Output their IDs and the total revenue.

>> Link to Question: https://platform.stratascratch.com/coding/2119-most-lucrative-products?code_type=3

>> Expected Output:

| product_id | revenue |
|------------|---------|
|     2      |   207   |
|     3      |   201   |
|     5      |   199   |
|     1      |    65   |
|     6      |    56   |

>> My Solution:
SELECT product_id,
       SUM(cost_in_dollars * units_sold) AS total_revenue
FROM 
    online_orders
WHERE 
    (MONTH(date) >= 1) AND (MONTH(date) <= 6)
GROUP BY 
    product_id
ORDER BY 
    total_revenue DESC
LIMIT 
    5;

# Question:
Find the second highest salary of employees.

>> Link to Question: https://platform.stratascratch.com/coding/9892-second-highest-salary?code_type=3

>> Expected Output:

|  salary   |
|-----------|
|  200,000  |


>> My Solution:
SELECT salary AS second_highest_salary
FROM 
    (
    SELECT salary, 
            RANK() OVER(ORDER BY salary DESC) AS salary_rank
    FROM 
        employee
    ) tmp
WHERE 
    salary_rank = 2;

# Question:
Which user flagged the most distinct videos that ended up approved by YouTube? Output, in one column, their full name or names in case of a tie. 
In the user's full name, include a space between the first and the last name.

>> Link to Question: https://platform.stratascratch.com/coding/2104-user-with-most-approved-flags?code_type=3

>> Expected Output
+--------------+
|   username   |
+--------------+
|   Mark May   |
| Richard Hasson|
+--------------+

>> My Solution:
WITH ranked_user AS 
(SELECT CONCAT(flag.user_firstname, ' ', flag.user_lastname) AS user_name,
        RANK() OVER(ORDER BY COUNT(DISTINCT(video_id)) DESC) AS user_flagged_rank
        -- rank the user by the count of distinct flagged video 
FROM 
    user_flags flag 
INNER JOIN 
    flag_review review 
ON 
    flag.flag_id = review.flag_id
WHERE 
    review.reviewed_outcome = 'APPROVED'
GROUP BY 
    CONCAT(flag.user_firstname, ' ', flag.user_lastname)
)

SELECT 
      user_name
FROM 
      ranked_user
WHERE 
      user_flagged_rank = 1;

# Question:
Find the top 5 businesses with most reviews. Assume that each row has a unique business_id such that the total reviews for each business is listed on each row. 
Output the business name along with the total number of reviews and order your results by the total reviews in descending order.

>> Link to Question: https://platform.stratascratch.com/coding/10048-top-businesses-with-most-reviews?code_type=3

>> Expected Output:
+-------------------------+--------------+
|          name           | review_count |
+-------------------------+--------------+
|      Iron Chef          |     331      |
| Jacs Dining and Tap House|     197      |
| Grimaldi's Pizzeria     |     187      |
|   Signs Restaurant       |     120      |
|        Kassab's         |     101      |
+-------------------------+--------------+

>> My Solution:
WITH business_rank AS
(SELECT name AS business_name,
        SUM(review_count) AS total_reviews,
       -- sum up the total reviews for each business
        RANK() OVER(ORDER BY SUM(review_count) DESC) AS  business_rank_by_num_reviews
       -- rank the each business by total number of reviews
FROM 
    yelp_business
GROUP BY 
    name
)

SELECT business_name,
       total_reviews
FROM 
    business_rank
WHERE 
    business_rank_by_num_reviews < 6;

# Question:
Find the email activity rank for each user. Email activity rank is defined by the total number of emails sent. The user with the highest number of emails sent will 
have a rank of 1, and so on. Output the user, total emails, and their activity rank. Order records by the total emails in descending order. Sort users with the same 
number of emails in alphabetical order.
In your rankings, return a unique value (i.e., a unique rank) even if multiple users have the same number of emails. For tie breaker use alphabetical order of the user usernames.

>> Link to Question: https://platform.stratascratch.com/coding/10351-activity-rank?code_type=3

>> Expected Output:
+------------------+--------------+----------------------------------+
|    from_user    | total_emails | activity_rank                     |
+------------------+--------------+----------------------------------+
| 32ded68d89443e808 |     19       |                1                 |
| ef5fe98c6b9f313075 |     19       |                2                 |
| 5b8754928306a18b68 |     18       |                3                 |
| 55e60cfcc9dc49c17e |     16       |                4                 |
| 91f59516cb9dee1e88 |     16       |                5                 |
+------------------+--------------+----------------------------------+

>> My Solution:
SELECT from_user AS user,
       COUNT(id) AS total_emails_sent_by_user,
       ROW_NUMBER() OVER(ORDER BY COUNT(id) DESC, from_user ASC) AS user_activity_rank
       -- row number will give unique rank to each user by considering total_emails_sent_by_user
FROM 
    google_gmail_emails
GROUP BY 
    from_user;

# Question:
Find the top 5 states with the most 5 star businesses. Output the state name along with the number of 5-star businesses and order records by the number of 5-star businesses 
in descending order. In case there are ties in the number of businesses, return all the unique states. If two states have the same result, sort them in alphabetical order.

>> Link to Question: https://platform.stratascratch.com/coding/10046-top-5-states-with-5-star-businesses?code_type=3

>> Expected Output:
All required columns and the first 5 rows of the solution are shown
+-------+------------------+
| state | five_star_counts |
+-------+------------------+
|  AZ   |       10         |
|  ON   |        5         |
|  NV   |        4         |
|  IL   |        3         |
|  OH   |        3         |
+-------+------------------+

>> My Solution:
WITH state_businesses AS
(SELECT state,
       COUNT(business_id) AS num_5_star_businesses,
       RANK() OVER(ORDER BY COUNT(business_id) DESC) AS state_rank
       -- RANK() function calculates state rank depending on number of 5 star business in that particular state
FROM 
    yelp_business
WHERE 
    stars = 5    -- filter the 5 star businesses from table
GROUP BY 
    state
ORDER BY 
    num_5_star_businesses DESC, state ASC)
    
SELECT state,
    num_5_star_businesses
FROM 
    state_businesses
WHERE
    state_rank <= 5;

# Question:
The election is conducted in a city and everyone can vote for one or more candidates, or choose not to vote at all. Each person has 1 vote so if they vote for multiple candidates, 
their vote gets equally split across these candidates. For example, if a person votes for 2 candidates, these candidates receive an equivalent of 0.5 vote each.
Find out who got the most votes and won the election. Output the name of the candidate or multiple names in case of a tie. To avoid issues with a floating-point error you can 
round the number of votes received by a candidate to 3 decimal places.

>> Link to Question: https://platform.stratascratch.com/coding/2099-election-results?code_type=3

>> Expected Output:
All required columns and the first 5 rows of the solution are shown

+--------------+
|   Candidate   |
+--------------+
|   Christine   |
+--------------+


>> My Solution:
WITH cte1 AS
(SELECT voter, 
       candidate,
       ROW_NUMBER() OVER(PARTITION BY voter) AS num
       -- it will calculate how many candidates a voter has cast his vote for
FROM voting_results
WHERE candidate IS NOT NULL
       -- it will filter the rows where candidates choose not to vote at all
     ),

cte2 AS
(SELECT voter, 
        candidate,
        ROUND(1/MAX(num) OVER(PARTITION BY voter),3) AS votes
        -- it will split the vote equally among multiple candidates
FROM cte1),

cte3 AS
(SELECT candidate, 
        RANK() OVER(ORDER BY SUM(votes) DESC) AS candidate_rank_by_total_votes
        -- it will rank the candidate by total_votes  
FROM cte2 
GROUP BY candidate
)

SELECT candidate 
FROM 
    cte3
WHERE 
    candidate_rank_by_total_votes = 1;

# Question:
Select the most popular client_id based on a count of the number of users who have at least 50% of their events from the following list: 'video call received', 'video call sent', 
'voice call received', 'voice call sent'.

>> Link to Question: https://platform.stratascratch.com/coding/2029-the-most-popular-client_id-among-users-using-video-and-voice-calls?code_type=3

>> Expected Output:
+-----------+
| client_id |
+-----------+
| desktop   |
+-----------+

>> My Solution:
WITH cte1 AS 
(SELECT user_id, 
       client_id,
       SUM(CASE WHEN event_type IN ('video call received', 'video call sent', 'voice call   received', 'voice call sent')
           THEN 1 ELSE 0 END) AS desired_event,
       -- calculating number of desired events by user from each client
       COUNT(event_type) AS total_events
       -- calculating total number of events by user from each client
FROM fact_events
GROUP BY client_id, user_id
),
cte2 AS
(SELECT user_id, 
        client_id, 
        (desired_event/total_events)*100 AS desired_event_percentage
	-- calculating desired_event_percentage by each user from each client
FROM cte1
)
cte3 AS
(SELECT client_id, 
        COUNT(user_id) AS desired_users,
        -- counting the number of users having atleast 50 % desired_event_percentage for each client 
        RANK() OVER(ORDER BY COUNT(user_id) DESC) AS client_rank
        -- ranking the client on the basis of count of users with atleast 50 % desired_event_percentage
FROM cte2
WHERE desired_event_percentage >= 50 
GROUP BY client_id)

SELECT client_id 
FROM cte3
WHERE client_rank = 1; 

# Question:
Given a table of tweet data over a specified time period, calculate the 3-day rolling average of tweets for each user. 
Output the user ID, tweet date, and rolling averages rounded to 2 decimal places.

Notes:
A rolling average, also known as a moving average or running mean is a time-series technique that examines trends in data over a specified period of time.
In this case, we want to determine how the tweet count for each user changes over a 3-day period.

>> Creating Table:
CREATE TABLE tweets (
    user_id INTEGER,
    tweet_date TIMESTAMP,
    tweet_count INTEGER
);

>> Inserting Data:
INSERT INTO tweets (user_id, tweet_date, tweet_count)
VALUES
    (111, '2022-06-01 00:00:00', 2),
    (111, '2022-06-02 00:00:00', 1),
    (111, '2022-06-03 00:00:00', 3),
    (111, '2022-06-04 00:00:00', 4),
    (111, '2022-06-05 00:00:00', 5);

>> Expected Output:
+---------+---------------------+----------------+
| user_id |     tweet_date      | rolling_avg_3d |
+---------+---------------------+----------------+
|  111    | 06/01/2022 00:00:00 |     2.00       |
|  111    | 06/02/2022 00:00:00 |     1.50       |
|  111    | 06/03/2022 00:00:00 |     2.00       |
|  111    | 06/04/2022 00:00:00 |     2.67       |
|  111    | 06/05/2022 00:00:00 |     4.00       |
+---------+---------------------+----------------+

>> My Solution:
SELECT user_id,
	     tweet_date,
	     ROUND(AVG(tweet_count) OVER(PARTITION BY user_id ORDER BY tweet_date
					 ROWS BETWEEN 2 PRECEDING AND CURRENT ROW),
		   2) AS rolling_average
FROM tweets;
