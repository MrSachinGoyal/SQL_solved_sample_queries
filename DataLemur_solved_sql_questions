# Question: 
Assume you are given the table below on Uber transactions made by users. Write a query to obtain the third transaction of every user. 
Output the user id, spend and transaction date.

>> Creating the Table:
CREATE TABLE transactions (
  user_id INTEGER,
  spend DECIMAL,
  transaction_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO transactions (user_id, spend, transaction_date)
VALUES
  (111, 100.50, '2022-01-08 12:00:00'),
  (111, 55.00, '2022-01-10 12:00:00'),
  (121, 36.00, '2022-01-18 12:00:00'),
  (145, 24.99, '2022-01-26 12:00:00'),
  (111, 89.60, '2022-02-05 12:00:00');

>> My Solution:
WITH transaction_rank AS (SELECT *,
                          ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY transaction_date ASC) AS transaction_number
                          FROM transactions)
  
SELECT user_id, spend, transaction_date
FROM transaction_rank
WHERE transaction_number = 3;


# Question:
Assume you're given tables with information on Snapchat users, including their ages and time spent sending and opening snaps.
Write a query to obtain a breakdown of the time spent sending vs. opening snaps as a percentage of total time spent on these activities grouped by age group. 
Round the percentage to 2 decimal places in the output.

Notes:
Calculate the following percentages:
time spent sending / (Time spent sending + Time spent opening)
Time spent opening / (Time spent sending + Time spent opening)
To avoid integer division in percentages, multiply by 100.0 and not 100.

>> Creating the Table:
CREATE TABLE activities (
activity_id INTEGER,
user_id INTEGER,
activity_type VARCHAR(10),
time_spent FLOAT,
activity_date TIMESTAMP
);

CREATE TABLE age_breakdown (
user_id INTEGER,
age_bucket VARCHAR(10)
);

>> Inserting Data:
INSERT INTO activities (activity_id, user_id, activity_type, time_spent, activity_date)
VALUES
(7274, 123, 'open', 4.50, '2022-06-22 12:00:00'),
(2425, 123, 'send', 3.50, '2022-06-22 12:00:00'),
(1413, 456, 'send', 5.67, '2022-06-23 12:00:00'),
(1414, 789, 'chat', 11.00, '2022-06-25 12:00:00'),
(2536, 456, 'open', 3.00, '2022-06-25 12:00:00');

INSERT INTO age_breakdown (user_id, age_bucket)
VALUES
(123, '31-35'),
(456, '26-30'),
(789, '21-25');

>> My Solution:
WITH cte AS (SELECT t1.age_bucket, t2.user_id, t2.activity_type, t2.time_spent,
      			 SUM(time_spent) OVER(PARTITION BY age_bucket ORDER BY age_bucket ASC) AS total_time_spent
      			 FROM age_breakdown t1
      			 INNER JOIN 
      			 activities t2
      			 ON t1.user_id = t2.user_id
      			 WHERE activity_type IN ('send', 'open'))
			
SELECT age_bucket,
	   ROUND(SUM(CASE WHEN activity_type = 'send' THEN (time_spent*100.0)/total_time_spent ELSE NULL END),2) AS send_percent,
	   ROUND(SUM(CASE WHEN activity_type = 'open' THEN (time_spent*100.0)/total_time_spent ELSE NULL END),2) AS open_percent
FROM cte
GROUP BY age_bucket;

# Question:
Assume you're given a table containing data on Amazon customers and their spending on products in different category, write a query to identify the top two highest-grossing products 
within each category in the year 2022. 
The output should include the category, product, and total spend.

>> Creating Table:
CREATE TABLE product_spend (
  category VARCHAR(255),
  product VARCHAR(255),
  user_id INT,
  spend DECIMAL(10, 2),
  transaction_date TIMESTAMP
);

>>Inserting Data:
INSERT INTO product_spend (category, product, user_id, spend, transaction_date)
VALUES
  ('appliance', 'refrigerator', 165, 246.00, '2021-12-26 12:00:00'),
  ('appliance', 'refrigerator', 123, 299.99, '2022-03-02 12:00:00'),
  ('appliance', 'washing machine', 123, 219.80, '2022-03-02 12:00:00'),
  ('electronics', 'vacuum', 178, 152.00, '2022-04-05 12:00:00'),
  ('electronics', 'wireless headset', 156, 249.90, '2022-07-08 12:00:00'),
  ('electronics', 'vacuum', 145, 189.00, '2022-07-15 12:00:00');

>> My Solution:
SELECT category, product, total_spend
FROM
	(SELECT category, 
	        product, 
	        SUM(spend) AS total_spend,
	        RANK() OVER(PARTITION BY category ORDER BY SUM(spend) DESC) AS rank_by_total_spend
	FROM product_spend
	WHERE EXTRACT(YEAR FROM transaction_date) = 2022
	GROUP BY 1, 2) tmp
WHERE rank_by_total_spend < 3;

# Question:
Assume you're given a table Twitter tweet data, write a query to obtain a histogram of tweets posted per user in 2022. Output the tweet count per user as the bucket and the number of 
Twitter users who fall into that bucket. In other words, group the users by the number of tweets they posted in 2022 and count the number of users in each group.

>> Creating Table:
CREATE TABLE tweets (
    tweet_id INTEGER,
    user_id INTEGER,
    msg VARCHAR(1000),
    tweet_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO tweets (tweet_id, user_id, msg, tweet_date)
	VALUES
		(214252, 111, 'Am considering taking Tesla private at $420. Funding secured.', '2021-12-30 00:00:00'),
		(739252, 111, 'Despite the constant negative press covfefe', '2022-01-01 00:00:00'),
		(846402, 111, 'Following @NickSinghTech on Twitter changed my life!', '2022-02-14 00:00:00'),
		(241425, 254, 'If the salary is so competitive why wonâ€™t you tell me what it is?', '2022-03-01 00:00:00'),
		(231574, 148, 'I no longer have a manager. I can''t be managed', '2022-03-23 00:00:00');

>> My Solution:
WITH user_tweet_counts AS (SELECT user_id, 
						   		  COUNT(tweet_id) AS no_of_tweets_by_user
						   FROM tweets
						   WHERE EXTRACT(YEAR FROM tweet_date) = 2022
						   GROUP BY user_id)

SELECT no_of_tweets_by_user AS tweet_bucket,
       COUNT(user_id) AS num_users
FROM user_tweet_counts
GROUP BY tweet_bucket;

# Question:
Assume you're given a table containing information on Facebook user actions. 
Write a query to obtain number of monthly active users (MAUs) in July 2022, including the month in numerical format "1, 2, 3".

Hint: An active user is defined as a user who has performed actions such as 'sign-in', 'like', or 'comment' in both the current month and the previous month

>> Creating Table:
CREATE TABLE user_actions (
    user_id INTEGER,
    event_id INTEGER,
    event_type VARCHAR(255),
    event_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO user_actions (user_id, event_id, event_type, event_date)
VALUES
    (445, 7765, 'sign-in', '2022-05-31 12:00:00'),
    (742, 6458, 'sign-in', '2022-06-03 12:00:00'),
    (445, 3634, 'like', '2022-06-05 12:00:00'),
    (742, 1374, 'comment', '2022-06-05 12:00:00'),
    (648, 3124, 'like', '2022-06-18 12:00:00');

>> My Solution:
WITH active_users AS (
    SELECT user_id, 
           EXTRACT(month FROM event_date) AS month, 
           COUNT(EVENT_ID) AS num_events
    FROM USER_actions
    WHERE event_type IN ('sign-in', 'like', 'comment')
    GROUP BY user_id, EXTRACT(month FROM event_date)
    ORDER BY user_id
)

SELECT month, 
       COUNT(user_id) AS monthly_active_users
FROM (
    SELECT *,
           month - LAG(month, 1) OVER(PARTITION BY USER_ID ORDER BY month) AS month_diff
    FROM active_users
) tmp
WHERE month_diff = 1 AND month = 7
GROUP BY month;

# Question:
Assume there are three Spotify tables: artists, songs, and global_song_rank, which contain information about the artists, songs, and music charts, respectively.

Write a query to find the top 5 artists whose songs appear most frequently in the Top 10 of the global_song_rank table. Display the top 5 artist names in ascending order, 
along with their song appearance ranking.

Assumptions:
If two or more artists have the same number of song appearances, they should be assigned the same ranking, and the rank numbers should be continuous (i.e. 1, 2, 2, 3, 4, 5).
For instance, if both Ed Sheeran and Bad Bunny appear in the Top 10 five times, they should both be ranked 1st and the next artist should be ranked 2nd.

>> Creating Table:
CREATE TABLE artists (
    artist_id INTEGER,
    artist_name VARCHAR(255),
    label_owner VARCHAR(255)
);

CREATE TABLE songs (
    song_id INTEGER PRIMARY KEY,
    artist_id INTEGER,
    name VARCHAR(255)
);

CREATE TABLE global_song_rank (
    day INTEGER CHECK (day >= 1 AND day <= 52),
    song_id INTEGER,
    rank INTEGER CHECK (rank >= 1 AND rank <= 1000000)
);

>> Inserting data:
INSERT INTO artists (artist_id, artist_name, label_owner)
VALUES
    (101, 'Ed Sheeran', 'Warner Music Group'),
    (120, 'Drake', 'Warner Music Group'),
    (125, 'Bad Bunny', 'Rimas Entertainment');

INSERT INTO songs (song_id, artist_id, name)
VALUES
    (55511, 101, 'Perfect'),
    (45202, 101, 'Shape of You'),
    (22222, 120, 'One Dance'),
    (19960, 120, 'Hotline Bling');

INSERT INTO global_song_rank (day, song_id, rank)
VALUES
    (1, 45202, 5),
    (3, 45202, 2),
    (1, 19960, 3),
    (9, 19960, 15);

>> My Solution:
WITH top_ten AS (SELECT a.artist_name,
				         DENSE_RANK() OVER(ORDER BY COUNT(*) DESC) AS rank_by_num_song_appearences
								 FROM artists a 
								 INNER JOIN songs s 
								 ON a.artist_id = s.artist_id
								 INNER JOIN global_song_rank gsr
								 ON s.song_id = gsr.song_id
								 WHERE gsr.rank < 11 
								 GROUP BY a.artist_name)
					 
SELECT * FROM top_ten 
WHERE rank_by_num_song_appearences < 6;

# Question:
Assume you're given a table containing information about Wayfair user transactions for different products. 
Write a query to calculate the year-on-year growth rate for the total spend of each product, grouping the results by product ID.
The output should include the year in ascending order, product ID, current year's spend, previous year's spend and year-on-year growth percentage, rounded to 2 decimal places.

>> Creating Table:
CREATE TABLE user_transactions (
    transaction_id INTEGER,
    product_id INTEGER,
    spend DECIMAL(10, 2),
    transaction_date TIMESTAMP
);

>> Inserting Data:
INSERT INTO user_transactions (transaction_id, product_id, spend, transaction_date)
VALUES
    (1341, 123424, 1500.60, '2019-12-31 12:00:00'),
    (1423, 123424, 1000.20, '2020-12-31 12:00:00'),
    (1623, 123424, 1246.44, '2021-12-31 12:00:00'),
    (1322, 123424, 2145.32, '2022-12-31 12:00:00');

>> My Solution:
WITH product_spend_cte AS (SELECT EXTRACT(YEAR FROM transaction_date) AS year,
              								    product_id,
              								    SUM(spend) AS current_year_spend_on_product,
              								    LAG(SUM(spend), 1) OVER(PARTITION BY product_id 
              														                ORDER BY EXTRACT(YEAR FROM transaction_date) ASC) AS previous_year_spend_on_product
              						 FROM user_transactions
              						 GROUP BY product_id, EXTRACT(YEAR FROM transaction_date))
							
SELECT *, 
	     ROUND(((current_year_spend_on_product - previous_year_spend_on_product)*100)/previous_year_spend_on_product, 2) AS year_on_year_growth_rate
FROM product_spend_cte;

# Question:
A Microsoft Azure Supercloud customer is defined as a company that purchases at least one product from each product category.
Write a query that effectively identifies the company ID of such Supercloud customers.

>> Creating Table:
CREATE TABLE customer_contracts (
    customer_id INTEGER,
    product_id INTEGER,
    amount INTEGER
);

CREATE TABLE products (
    product_id INTEGER,
    product_category VARCHAR(255),
    product_name VARCHAR(255)
);

>> Inserting Data:
INSERT INTO customer_contracts (customer_id, product_id, amount)
VALUES
    (1, 1, 1000),
    (1, 3, 2000),
    (1, 5, 1500),
    (2, 2, 3000),
    (2, 6, 2000);

INSERT INTO products (product_id, product_category, product_name)
VALUES
    (1, 'Analytics', 'Azure Databricks'),
    (2, 'Analytics', 'Azure Stream Analytics'),
    (4, 'Containers', 'Azure Kubernetes Service'),
    (5, 'Containers', 'Azure Service Fabric'),
    (6, 'Compute', 'Virtual Machines'),
    (7, 'Compute', 'Azure Functions');

>> My Solution:
SELECT cc.customer_id
FROM customer_contracts cc
INNER JOIN products p
ON cc.product_id = p.product_id
GROUP BY cc.customer_id
HAVING COUNT(DISTINCT p.product_category) = (SELECT COUNT(DISTINCT product_category) FROM products);

# Question:
Given a table of candidates and their skills, you're tasked with finding the candidates best suited for an open Data Science job. 
You want to find candidates who are proficient in Python, Tableau, and PostgreSQL.
Write a query to list the candidates who possess all of the required skills for the job. Sort the output by candidate ID in ascending order.

>> Creating Table:
CREATE TABLE candidates (
    candidate_id INTEGER,
    skill VARCHAR(255)
);

>> Inserting Data:
INSERT INTO candidates (candidate_id, skill)
VALUES
    (123, 'Python'),
    (123, 'Tableau'),
    (123, 'PostgreSQL'),
    (234, 'R'),
    (234, 'PowerBI'),
    (234, 'SQL Server'),
    (345, 'Python'),
    (345, 'Tableau');

>> My Solution:
SELECT candidate_id
FROM candidates
GROUP BY candidate_id
HAVING SUM(CASE WHEN skill in ('Python', 'Tableau', 'PostgreSQL') THEN 1 ELSE 0 END) = 3
ORDER BY candidate_id;

# Question:
Amazon wants to maximize the number of items it can stock in a 500,000 square feet warehouse. It wants to stock as many prime items as possible, and afterwards use the remaining 
square footage to stock the most number of non-prime items.

Write a query to find the number of prime and non-prime items that can be stored in the 500,000 square feet warehouse. Output the item type with prime_eligible followed by not_prime 
and the maximum number of items that can be stocked.

Assumptions:
-- Prime and non-prime items have to be stored in equal amounts, regardless of their size or square footage. This implies that prime items will be stored separately from non-prime 
   items in their respective containers, but within each container, all items must be in the same amount.
-- Non-prime items must always be available in stock to meet customer demand, so the non-prime item count should never be zero.
-- Item count should be whole numbers (integers).

>> Creating Table:
CREATE TABLE inventory (
    item_id INTEGER,
    item_type VARCHAR(255),
    item_category VARCHAR(255),
    square_footage DECIMAL
);

>> Inserting Data:
INSERT INTO inventory (item_id, item_type, item_category, square_footage)
VALUES
    (1374, 'prime_eligible', 'mini refrigerator', 68.00),
    (4245, 'not_prime', 'standing lamp', 26.40),
    (2452, 'prime_eligible', 'television', 85.00),
    (3255, 'not_prime', 'side table', 22.60),
    (1672, 'prime_eligible', 'laptop', 8.50);

>> My Solution:
WITH cte AS (SELECT item_type, COUNT(*) AS no_of_items,
			 SUM(square_footage) AS container_space, 500000 as total_sq_foot
			 FROM inventory
			 GROUP BY item_type
			 ORDER BY item_type DESC)
			 
SELECT item_type,
CASE WHEN item_type = 'prime_eligible' THEN FLOOR((total_sq_foot/container_space)) * no_of_items
ELSE FLOOR(
        	 (total_sq_foot - ( 
                					   SELECT container_space * FLOOR((total_sq_foot/container_space))
                					   FROM cte
                					   WHERE item_type = 'prime_eligible'
                					  )
        	 )/container_space
        	 ) * no_of_items
END AS item_count;

# Question:
Tesla is investigating production bottlenecks and they need your help to extract the relevant data. 
Write a query to determine which parts have begun the assembly process but are not yet finished.

Assumptions:
-- parts_assembly table contains all parts currently in production, each at varying stages of the assembly process.
-- An unfinished part is one that lacks a finish_date.

>> Creating Table:
CREATE TABLE parts_assembly (
    part VARCHAR(255),      
    finish_date TIMESTAMP,   
    assembly_step INT    
);

>> Inserting Table:
INSERT INTO parts_assembly (part, finish_date, assembly_step)
VALUES ('battery', '2022-01-22 00:00:00', 1),
       ('battery', '2022-02-22 00:00:00', 2),
       ('battery', '2022-03-22 00:00:00', 3),
       ('bumper', '2022-01-22 00:00:00', 1),
       ('bumper', '2022-02-22 00:00:00', 2),
       ('bumper', NULL, 3),
       ('bumper', NULL, 4);
	   
>> My Solution:
SELECT part,
	     assembly_step
FROM parts_assembly
WHERE finish_date IS NULL;

# Question:
Google's marketing team is making a Superbowl commercial and needs a simple statistic to put on their TV ad: the median number of searches a person made last year.
However, at Google scale, querying the 2 trillion searches is too costly. Luckily, you have access to the summary table which tells you the number of searches made last year and 
how many Google users fall into that bucket.
Write a query to report the median of searches made by a user. Round the median to one decimal point.

>> Creating table:
CREATE TABLE search_frequency (
    searches integer,
    num_users integer
);

>> Inserting data:
INSERT INTO search_frequency (searches, num_users)
VALUES
    (1, 2),
    (2, 2),
    (3, 3),
    (4, 1);

>> My Solution:
SELECT 
	(CAST (PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY searches) AS DECIMAL (6,1))) AS  median_searches 
FROM
(SELECT searches,
        GENERATE_SERIES(1, num_users) AS num_users
FROM search_frequency) tmp;

# Question:
Your team at JPMorgan Chase is soon launching a new credit card. You are asked to estimate how many cards you'll issue in the first month.
Before you can answer this question, you want to first get some perspective on how well new credit card launches typically do in their first month.

Write a query that outputs the name of the credit card, and how many cards were issued in its launch month. 
The launch month is the earliest record in the monthly_cards_issued table for a given card. Order the results starting from the biggest issued amount.

>> Creating Table:
CREATE TABLE monthly_cards_issued (
    issue_month INTEGER,
    issue_year INTEGER,
    card_name VARCHAR(255),
    issued_amount INTEGER
);

>> Inserting Data:
INSERT INTO monthly_cards_issued (issue_month, issue_year, card_name, issued_amount)
VALUES
    (1, 2021, 'Chase Sapphire Reserve', 170000),
    (2, 2021, 'Chase Sapphire Reserve', 175000),
    (3, 2021, 'Chase Sapphire Reserve', 180000),
    (3, 2021, 'Chase Freedom Flex', 65000),
    (4, 2021, 'Chase Freedom Flex', 70000);

>> My Solution:
SELECT card_name, issued_amount
FROM monthly_cards_issued
WHERE (card_name, 
       CAST(CONCAT(issue_year, '-', issue_month, '-', 1) AS DATE)) 
IN (SELECT card_name, 
	    MIN(CAST(CONCAT(issue_year, '-', issue_month, '-', 1) AS DATE)) AS first_issue_date
    FROM monthly_cards_issued
    GROUP BY card_name)
    ORDER BY issued_amount DESC;

# Question:
Assume you're given a table with measurement values obtained from a Google sensor over multiple days with measurements taken multiple times within each day.

Write a query to calculate the sum of odd-numbered and even-numbered measurements separately for a particular day and display the results in two different columns. 
Refer to the Example Output below for the desired format.

Definition:
Within a day, measurements taken at 1st, 3rd, and 5th times are considered odd-numbered measurements, and measurements taken at 2nd, 4th, and 6th times are considered even-numbered 
measurements.

>> Creating table:
CREATE TABLE measurements (
    measurement_id INTEGER,
    measurement_value DECIMAL,
    measurement_time TIMESTAMP
);

>> Inserting Data:
INSERT INTO measurements (measurement_id, measurement_value, measurement_time)
VALUES
    (131233, 1109.51, '2022-07-10 09:00:00'),
    (135211, 1662.74, '2022-07-10 11:00:00'),
    (523542, 1246.24, '2022-07-10 13:15:00'),
    (143562, 1124.50, '2022-07-11 15:00:00'),
    (346462, 1234.14, '2022-07-11 16:45:00');

>> My Solution:
WITH cte AS (SELECT CAST(DATE(measurement_time) AS TIMESTAMP) AS measurement_day,
				   	        measurement_value,
				   	        ROW_NUMBER() OVER(PARTITION BY DATE(measurement_time) 
									                    ORDER BY measurement_time ASC) AS measurement_num
			       FROM measurements)

SELECT measurement_day,
       SUM(CASE WHEN (measurement_num % 2 != 0) THEN measurement_value 
                ELSE 0 
                END) AS sum_odd,
       SUM(CASE WHEN (measurement_num % 2 = 0) THEN measurement_value 
                ELSE 0 
                END) AS sum_even
FROM cte
GROUP BY measurement_day
ORDER BY measurement_day;

# Question:
New TikTok users sign up with their emails. They confirmed their signup by replying to the text confirmation to activate their accounts. Users may receive multiple text messages 
for account confirmation until they have confirmed their new account.
A senior analyst is interested to know the activation rate of specified users in the emails table. Write a query to find the activation rate. Round the percentage to 2 decimal places.

Definitions:
emails table contain the information of user signup details.
texts table contains the users' activation information.

Assumptions:
The analyst is interested in the activation rate of specific users in the emails table, which may not include all users that could potentially be found in the texts table.
For example, user 123 in the emails table may not be in the texts table and vice versa.

>> Creating Table:
CREATE TABLE emails (
    email_id INTEGER,
    user_id INTEGER,
    signup_date TIMESTAMP
);

CREATE TABLE texts (
    text_id INTEGER,
    email_id INTEGER,
    signup_action VARCHAR(255) 
);

>> Inserting Data:
INSERT INTO emails (email_id, user_id, signup_date)
VALUES
    (125, 7771, '2022-06-14 00:00:00'),
    (236, 6950, '2022-07-01 00:00:00'),
    (433, 1052, '2022-07-09 00:00:00');

INSERT INTO texts (text_id, email_id, signup_action)
VALUES
    (6878, 125, 'Confirmed'),
    (6920, 236, 'Not Confirmed'),
    (6994, 236, 'Confirmed');

>> My Solution:
WITH user_activation_status AS (
    SELECT e.user_id, t.signup_action
    FROM emails e
    LEFT JOIN texts t ON e.email_id = t.email_id
    WHERE e.email_id IS NOT NULL 
),    
cte1 AS (
    SELECT COUNT(user_id) AS total_confirmed_users
    FROM user_activation_status
    WHERE signup_action = 'Confirmed'
),
cte2 AS (
    SELECT COUNT(DISTINCT user_id) AS total_num_users
    FROM user_activation_status
)

SELECT ROUND(CAST(total_confirmed_users AS DECIMAL) / total_num_users, 2) AS activation_percentage
FROM cte1, cte2;



